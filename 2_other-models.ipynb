{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64cff75c-7ca8-4e2e-a70b-c7d1f25e57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Stuff\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import numcodecs\n",
    "\n",
    "## HEALPix Specific\n",
    "import healpix as hp\n",
    "import easygems.healpix as egh\n",
    "import easygems.remap as egr\n",
    "\n",
    "import intake     # For catalogs\n",
    "import zarr\n",
    "\n",
    "# Ilan\n",
    "from icecream import ic\n",
    "import nc_time_axis\n",
    "\n",
    "def worldmap(var, title='', cbar_title='', **kwargs):\n",
    "    #projection = ccrs.Robinson(central_longitude=-135.5808361)\n",
    "    projection = ccrs.Robinson(central_longitude=0)\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(8, 4), subplot_kw={\"projection\": projection}, constrained_layout=True\n",
    "    )\n",
    "    ax.set_global()\n",
    "    ax.set_title(title)\n",
    "\n",
    "    hpshow = egh.healpix_show(var, ax=ax, **kwargs)\n",
    "    cbar = plt.colorbar(hpshow, ax=ax, orientation='vertical', \n",
    "                    pad=0.05, shrink=0.8, label=cbar_title)\n",
    "    ax.add_feature(cf.COASTLINE, linewidth=0.8)\n",
    "    ax.add_feature(cf.BORDERS, linewidth=0.4)\n",
    "    \n",
    "def usmap(var, title='', cbar_title='', **kwargs):\n",
    "    #projection = ccrs.Robinson(central_longitude=-135.5808361)\n",
    "    #projection = ccrs.Robinson(central_longitude=-90)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(8, 4), subplot_kw={\"projection\": projection}, constrained_layout=True\n",
    "    )\n",
    "    ax.set_extent([-110, -60, 20, 45])\n",
    "    \n",
    "    hpshow = egh.healpix_show(var, ax=ax, **kwargs)\n",
    "    cbar = plt.colorbar(hpshow, ax=ax, orientation='vertical', \n",
    "                    pad=0.05, shrink=0.8, label=cbar_title)\n",
    "    ax.set_title(title)\n",
    "    ax.add_feature(cf.COASTLINE, linewidth=0.8)\n",
    "    #ax.coastlines(linewidth=0.8)\n",
    "    ax.add_feature(cf.BORDERS, linewidth=0.4)\n",
    "    ax.add_feature(cf.STATES, linewidth=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad2efa3-932c-47e5-af2e-cf85e4d79e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "# cluster = LocalCluster()\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2a2c8c-b0e7-4744-864b-7a5a99343a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xsh24_coarse', 'xsh24_native', 'xsh21_coarse', 'scream2D_hrly', 'scream_ne120', 'scream_lnd', 'ifs_fesom', 'icon_3hp003']\n"
     ]
    }
   ],
   "source": [
    "catfn='/home/tmerlis/hackathon/hackathon_cat_may14_main.yaml'\n",
    "\n",
    "combo_cat = intake.open_catalog(catfn)\n",
    "# ICON and IFS\n",
    "print (list(combo_cat)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767ff3f0-3425-40b3-bef4-c55331851330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iv4111/.conda/envs/easy25/lib/python3.12/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/iv4111/.conda/envs/easy25/lib/python3.12/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4TB\n",
      "Dimensions:   (time: 10201, cell: 196608, level_snow: 5, level: 25)\n",
      "Coordinates:\n",
      "    lat       (cell) float64 2MB 0.2984 0.5968 0.5968 ... -0.5968 -0.2984\n",
      "  * level     (level) float32 100B 1.0 5.0 10.0 20.0 ... 925.0 950.0 975.0 1e+03\n",
      "    lon       (cell) float64 2MB 45.0 45.35 44.65 45.0 ... 315.4 314.6 315.0\n",
      "  * time      (time) datetime64[ns] 82kB 2020-01-01 ... 2021-03-01\n",
      "    crs       int64 8B 0\n",
      "  * cell      (cell) int64 2MB 0 1 2 3 4 ... 196603 196604 196605 196606 196607\n",
      "Dimensions without coordinates: level_snow\n",
      "Data variables: (12/83)\n",
      "    100si     (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    100u      (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    100v      (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    10si      (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    2d        (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    avg_sd24  (level_snow, cell) float32 4MB dask.array<chunksize=(5, 4096), meta=np.ndarray>\n",
      "    ...        ...\n",
      "    vas       (time, cell) float32 8GB dask.array<chunksize=(168, 4096), meta=np.ndarray>\n",
      "    wa        (time, level, cell) float32 201GB dask.array<chunksize=(168, 5, 4096), meta=np.ndarray>\n",
      "    z         (cell) float32 786kB dask.array<chunksize=(196608,), meta=np.ndarray>\n",
      "    zg        (time, level, cell) float32 201GB dask.array<chunksize=(168, 5, 4096), meta=np.ndarray>\n",
      "    wind      (time, level, cell) float32 201GB dask.array<chunksize=(168, 5, 4096), meta=np.ndarray>\n",
      "    height    (time, level, cell) float32 201GB dask.array<chunksize=(168, 5, 4096), meta=np.ndarray>\n",
      "<xarray.Dataset> Size: 105GB\n",
      "Dimensions:       (time: 425, cell: 196608, pressure: 30, pressure_rva: 3)\n",
      "Coordinates:\n",
      "  * pressure      (pressure) int64 240B 5 10 20 50 ... 92500 95000 97500 100000\n",
      "  * pressure_rva  (pressure_rva) int64 24B 16 18 23\n",
      "  * time          (time) datetime64[ns] 3kB 2020-01-02 2020-01-03 ... 2021-03-01\n",
      "    crs           int64 8B 0\n",
      "  * cell          (cell) int64 2MB 0 1 2 3 4 ... 196604 196605 196606 196607\n",
      "    lat           (cell) float64 2MB 0.2984 0.5968 0.5968 ... -0.5968 -0.2984\n",
      "    lon           (cell) float64 2MB 45.0 45.35 44.65 45.0 ... 315.4 314.6 315.0\n",
      "Data variables: (12/25)\n",
      "    egpvi         (time, cell) float32 334MB dask.array<chunksize=(425, 3072), meta=np.ndarray>\n",
      "    einvi         (time, cell) float32 334MB dask.array<chunksize=(425, 3072), meta=np.ndarray>\n",
      "    ekhvi         (time, cell) float32 334MB dask.array<chunksize=(425, 3072), meta=np.ndarray>\n",
      "    ekvvi         (time, cell) float32 334MB dask.array<chunksize=(425, 3072), meta=np.ndarray>\n",
      "    hur           (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    hus           (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    ...            ...\n",
      "    va            (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    vas           (time, cell) float32 334MB dask.array<chunksize=(425, 3072), meta=np.ndarray>\n",
      "    wa            (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    zg            (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    wind          (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n",
      "    height        (time, pressure, cell) float32 10GB dask.array<chunksize=(425, 3, 1536), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "def preprocess(ds):\n",
    "    res = ds \\\n",
    "        .assign(wind=lambda x: np.sqrt(x['ua']**2 + x['va']**2)) \\\n",
    "        .assign(height=lambda x: x['zg']) # geopotential height (basically height)\n",
    "    return res\n",
    "    \n",
    "# select zoom level and the part of the combined catalog you're interested in\n",
    "# coarse stores are available at zoom 7 ~50km and lower\n",
    "#zoom_select = 7 # Wind speeds are messed up for zoom 7 and less\n",
    "ifs = combo_cat.ifs_fesom().to_dask().pipe(egh.attach_coords).pipe(preprocess)\n",
    "icon = combo_cat.icon_3hp003().to_dask().pipe(egh.attach_coords).pipe(preprocess)\n",
    "print(ifs)\n",
    "print(icon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47729b7-05cf-435d-acd5-4300ee1058ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lljs(c_winds, c_heights):\n",
    "    \"\"\"\n",
    "    Input: one cell of data, dim is [plev]\n",
    "    Output: dataset with 3 fields\n",
    "        1. mask [time, cell] -> True for jet, False for no\n",
    "        2. height [time, cell] -> height of the LLJ [m] (will always have data)\n",
    "        2. strength [time, cell] -> strength of the jet core [m/s] (will always have data)\n",
    "    \"\"\"\n",
    "    # Need increasing heights for np.interp to work\n",
    "    good_heights = c_heights >= 0\n",
    "    c_heights, c_winds = c_heights[good_heights], c_winds[good_heights]\n",
    "    sort_idx = np.argsort(c_heights)\n",
    "    c_heights, c_winds = c_heights[sort_idx], c_winds[sort_idx]\n",
    "    # Step 1 -> interpolate winds to specific height levels\n",
    "    heights = np.arange(10, 3010, 10) # 100m threshold\n",
    "    winds = np.interp(heights, c_heights, c_winds)\n",
    "    core_idx = np.nanargmax(winds)\n",
    "    # Get core properties\n",
    "    core_height = heights[core_idx]\n",
    "    if core_height > 1000: # will lead to index error\n",
    "        return (0, np.nan, np.nan)\n",
    "    core_speed = winds[core_idx]\n",
    "    # Get layer properties\n",
    "    buffer_idx = core_idx + 50 # 500 m buffer @ 10 m spacing\n",
    "    buffer_speed = winds[buffer_idx]\n",
    "    shear = np.gradient(winds, 10)[buffer_idx]\n",
    "    # Checks\n",
    "    jet = ((core_speed - buffer_speed) > 2) \\\n",
    "        & (core_height <= 1000) \\\n",
    "        & (core_height >= 50) \\\n",
    "        & (core_speed >= 10) \\\n",
    "        & (shear < 0.005)\n",
    "    if jet:\n",
    "        return (1, core_height, core_speed)\n",
    "    else:\n",
    "        return (0, np.nan, np.nan)\n",
    "\n",
    "def apply_lljs(wind, height, p_name):\n",
    "    jet_mask, jet_height, jet_speed = xr.apply_ufunc(\n",
    "        get_lljs,\n",
    "        wind.chunk({p_name:-1}),\n",
    "        height.chunk({p_name:-1}),\n",
    "        input_core_dims=[[p_name], [p_name]],\n",
    "        output_core_dims=[[], [], []],\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        output_dtypes=[bool, float, float],\n",
    "    )\n",
    "    return xr.merge([\n",
    "        jet_mask.rename('mask'),\n",
    "        jet_height.rename('height'), \n",
    "        jet_speed.rename('speed')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb1d22-650f-4084-8e0c-280752254f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################                        ] | 40% Completed | 14m 40ss\n"
     ]
    }
   ],
   "source": [
    "for ds, name, p_label in zip([ifs, icon], ['IFS', 'ICON'], ['level', 'pressure']):\n",
    "    us = ((ds.lat <= 50) & (ds.lat >= 20) & (ds.lon >= -130+360) & (ds.lon <= -60+360))\n",
    "    ds_us = ds.isel(cell=us)\n",
    "    llj = apply_lljs(ds_us.wind, ds_us.height, p_label)\n",
    "    llj['crs'].attrs = ds_us['crs'].attrs.copy() # need to copy attributes so healpix doesn't mess up\n",
    "    llj.to_netcdf(f'/scratch/cimes/iv4111/hk25-data/llj_{name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10f7eb-e5c0-489d-99dd-796edb2cab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds, name in zip([ifs, icon], ['IFS', 'ICON']):\n",
    "    llj = xr.open_dataset(f'/scratch/cimes/iv4111/hk25-data/llj_{name}.h5', chunks='auto')\n",
    "    freq = llj.mask.sum('time')/len(llj.time)*100\n",
    "    ### Only select regions where they occur >5% of the time ###\n",
    "    freq = freq.where(freq>5, np.nan)\n",
    "    llj = llj.where(freq>5, np.nan)\n",
    "    title = f'{name}'\n",
    "    usmap(freq, title=f'LLJ Occurrence {title}', cbar_title='Frequency [%]', vmin=0)\n",
    "    # Speed\n",
    "    usmap(llj.speed.mean('time'), title=f'LLJ Speed {title}', cbar_title=r'Mean Speed of LLJ [m s$^{-1}$]', vmin=0, cmap='plasma')\n",
    "    # Jet height\n",
    "    usmap(llj.height.mean('time'), title=f'LLJ Height {title}', cbar_title=r'Mean Height of LLJ [m]', vmin=0, cmap='cividis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy25 [~/.conda/envs/easy25/]",
   "language": "python",
   "name": "conda_easy25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
